{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_A2SZPmbD4Pk"
   },
   "source": [
    "<h1>Chapter 8 - Semantic Search and Retrieval-Augmented Generation</h1>\n",
    "<i>Exploring a vital part of LLMs, search.</i>\n",
    "\n",
    "<a href=\"https://www.amazon.com/Hands-Large-Language-Models-Understanding/dp/1098150961\"><img src=\"https://img.shields.io/badge/Buy%20the%20Book!-grey?logo=amazon\"></a>\n",
    "<a href=\"https://www.oreilly.com/library/view/hands-on-large-language/9781098150952/\"><img src=\"https://img.shields.io/badge/O'Reilly-white.svg?logo=data:image/svg%2bxml;base64,PHN2ZyB3aWR0aD0iMzQiIGhlaWdodD0iMjciIHZpZXdCb3g9IjAgMCAzNCAyNyIgZmlsbD0ibm9uZSIgeG1sbnM9Imh0dHA6Ly93d3cudzMub3JnLzIwMDAvc3ZnIj4KPGNpcmNsZSBjeD0iMTMiIGN5PSIxNCIgcj0iMTEiIHN0cm9rZT0iI0Q0MDEwMSIgc3Ryb2tlLXdpZHRoPSI0Ii8+CjxjaXJjbGUgY3g9IjMwLjUiIGN5PSIzLjUiIHI9IjMuNSIgZmlsbD0iI0Q0MDEwMSIvPgo8L3N2Zz4K\"></a>\n",
    "<a href=\"https://github.com/HandsOnLLM/Hands-On-Large-Language-Models\"><img src=\"https://img.shields.io/badge/GitHub%20Repository-black?logo=github\"></a>\n",
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/HandsOnLLM/Hands-On-Large-Language-Models/blob/main/chapter08/Chapter%208%20-%20Semantic%20Search.ipynb)\n",
    "\n",
    "---\n",
    "\n",
    "This notebook is for Chapter 8 of the [Hands-On Large Language Models](https://www.amazon.com/Hands-Large-Language-Models-Understanding/dp/1098150961) book by [Jay Alammar](https://www.linkedin.com/in/jalammar) and [Maarten Grootendorst](https://www.linkedin.com/in/mgrootendorst/).\n",
    "\n",
    "---\n",
    "\n",
    "<a href=\"https://www.amazon.com/Hands-Large-Language-Models-Understanding/dp/1098150961\">\n",
    "<img src=\"https://raw.githubusercontent.com/HandsOnLLM/Hands-On-Large-Language-Models/main/images/book_cover.png\" width=\"350\"/></a>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [OPTIONAL] - Installing Packages on <img src=\"https://colab.google/static/images/icons/colab.png\" width=100>\n",
    "\n",
    "If you are viewing this notebook on Google Colab (or any other cloud vendor), you need to **uncomment and run** the following codeblock to install the dependencies for this chapter:\n",
    "\n",
    "---\n",
    "\n",
    "ðŸ’¡ **NOTE**: We will want to use a GPU to run the examples in this notebook. In Google Colab, go to\n",
    "**Runtime > Change runtime type > Hardware accelerator > GPU > GPU type > T4**.\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%capture\n",
    "# !pip install langchain==0.2.5 faiss-cpu==1.8.0 cohere==5.5.8 langchain-community==0.2.5 rank_bm25==0.2.2 sentence-transformers==3.0.1\n",
    "# !pip install llama-cpp-python==0.2.78  --extra-index-url https://abetlen.github.io/llama-cpp-python/whl/cu124\n",
    "\n",
    "## IMPORTANT: Make sure to restart the session after installing the packages above."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ye0HbBr3EV0P"
   },
   "source": [
    "# Dense Retrieval Example\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Svgdo3y3F741"
   },
   "source": [
    "## 1. Getting the text archive and chunking it\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "id": "_Dcq1j_xFxIr"
   },
   "outputs": [],
   "source": [
    "text = \"\"\"\n",
    "Interstellar is a 2014 epic science fiction film co-written, directed, and produced by Christopher Nolan.\n",
    "It stars Matthew McConaughey, Anne Hathaway, Jessica Chastain, Bill Irwin, Ellen Burstyn, Matt Damon, and Michael Caine.\n",
    "Set in a dystopian future where humanity is struggling to survive, the film follows a group of astronauts who travel through a wormhole near Saturn in search of a new home for mankind.\n",
    "\n",
    "Brothers Christopher and Jonathan Nolan wrote the screenplay, which had its origins in a script Jonathan developed in 2007.\n",
    "Caltech theoretical physicist and 2017 Nobel laureate in Physics[4] Kip Thorne was an executive producer, acted as a scientific consultant, and wrote a tie-in book, The Science of Interstellar.\n",
    "Cinematographer Hoyte van Hoytema shot it on 35 mm movie film in the Panavision anamorphic format and IMAX 70 mm.\n",
    "Principal photography began in late 2013 and took place in Alberta, Iceland, and Los Angeles.\n",
    "Interstellar uses extensive practical and miniature effects and the company Double Negative created additional digital effects.\n",
    "\n",
    "Interstellar premiered on October 26, 2014, in Los Angeles.\n",
    "In the United States, it was first released on film stock, expanding to venues using digital projectors.\n",
    "The film had a worldwide gross over $677 million (and $773 million with subsequent re-releases), making it the tenth-highest grossing film of 2014.\n",
    "It received acclaim for its performances, direction, screenplay, musical score, visual effects, ambition, themes, and emotional weight.\n",
    "It has also received praise from many astronomers for its scientific accuracy and portrayal of theoretical astrophysics. Since its premiere, Interstellar gained a cult following,[5] and now is regarded by many sci-fi experts as one of the best science-fiction films of all time.\n",
    "Interstellar was nominated for five awards at the 87th Academy Awards, winning Best Visual Effects, and received numerous other accolades.\n",
    "\n",
    "The father in the movie went to space to find a new habitable planet for humanity. However, he left his family behind and got stranded in a different dimension.\n",
    "\"\"\"\n",
    "\n",
    "# Split into a list of sentences\n",
    "texts = text.split('.')\n",
    "\n",
    "# Clean up to remove empty spaces and new lines\n",
    "texts = [t.strip(' \\n') for t in texts]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "krDDOpcZF5qo"
   },
   "source": [
    "## 2. Embedding the Text Chunks, Creating Vector DB, Add and Query Data\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_huggingface import HuggingFaceEmbeddings\n",
    "from tqdm import tqdm\n",
    "\n",
    "embedding_model = HuggingFaceEmbeddings(\n",
    "    model_name='BAAI/bge-small-en-v1.5'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using Chroma's native API (will use LangChain Version after)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\USER\\AppData\\Local\\Temp\\ipykernel_113144\\624235270.py:9: DeprecationWarning: The class MyEmbeddingFunction does not implement __init__. This will be required in a future version.\n",
      "  embedding_function = MyEmbeddingFunction()\n"
     ]
    }
   ],
   "source": [
    "import chromadb\n",
    "from chromadb import Documents, EmbeddingFunction, Embeddings\n",
    "\n",
    "class MyEmbeddingFunction(EmbeddingFunction):\n",
    "    def __call__(self, input: Documents) -> Embeddings:\n",
    "        embeddings = embedding_model.embed_documents(input)\n",
    "        return embeddings\n",
    "    \n",
    "embedding_function = MyEmbeddingFunction()\n",
    "\n",
    "chroma_client = chromadb.PersistentClient(path=\"./chroma_db\")\n",
    "try:\n",
    "    chroma_client.delete_collection(name=\"my_collection\")\n",
    "except:\n",
    "    pass\n",
    "collection = chroma_client.create_collection(\n",
    "    name=\"my_collection\",\n",
    "    embedding_function=embedding_function\n",
    ")\n",
    "collection.add(\n",
    "    ids=[str(id) for id in range(len(texts))], \n",
    "    documents=texts\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "18"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(embedding_function(texts))  # should be 15"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ids': [['12', '4', '15']],\n",
       " 'embeddings': None,\n",
       " 'documents': [['It has also received praise from many astronomers for its scientific accuracy and portrayal of theoretical astrophysics',\n",
       "   'Caltech theoretical physicist and 2017 Nobel laureate in Physics[4] Kip Thorne was an executive producer, acted as a scientific consultant, and wrote a tie-in book, The Science of Interstellar',\n",
       "   'The father in the movie went to space to find a new habitable planet for humanity']],\n",
       " 'uris': None,\n",
       " 'included': ['metadatas', 'documents', 'distances'],\n",
       " 'data': None,\n",
       " 'metadatas': [[None, None, None]],\n",
       " 'distances': [[0.6178344488143921, 0.8098767995834351, 0.8817310333251953]]}"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# cannot handle too verbose of a query yet. need intermediate LLM to change query to more concise version later. Use concise query for now.\n",
    "collection.query(query_texts='how precise was the science', n_results=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "def search(query, number_of_results=3):\n",
    "  # 1. Get the query's embedding\n",
    "  query_embed = embedding_function([query])[0]\n",
    "\n",
    "  # 2. Retrieve the nearest neighbors\n",
    "  search_result = collection.query(query_texts=[query], n_results=number_of_results)\n",
    "\n",
    "  # 3. Format the results\n",
    "  results = pd.DataFrame(data={'texts': search_result['documents'][0],\n",
    "                              'distance': search_result['distances'][0]})\n",
    "\n",
    "  # 4. Print and return the results\n",
    "  print(f\"Query:'{query}'\\nNearest neighbors:\")\n",
    "  return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query:'how precise was the science'\n",
      "Nearest neighbors:\n"
     ]
    },
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "texts",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "distance",
         "rawType": "float64",
         "type": "float"
        }
       ],
       "ref": "852b1ab4-f01d-481a-a097-23654ac877b0",
       "rows": [
        [
         "0",
         "It has also received praise from many astronomers for its scientific accuracy and portrayal of theoretical astrophysics",
         "0.6178344488143921"
        ],
        [
         "1",
         "Caltech theoretical physicist and 2017 Nobel laureate in Physics[4] Kip Thorne was an executive producer, acted as a scientific consultant, and wrote a tie-in book, The Science of Interstellar",
         "0.8098767995834351"
        ],
        [
         "2",
         "The father in the movie went to space to find a new habitable planet for humanity",
         "0.8817310333251953"
        ]
       ],
       "shape": {
        "columns": 2,
        "rows": 3
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>texts</th>\n",
       "      <th>distance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>It has also received praise from many astronom...</td>\n",
       "      <td>0.617834</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Caltech theoretical physicist and 2017 Nobel l...</td>\n",
       "      <td>0.809877</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>The father in the movie went to space to find ...</td>\n",
       "      <td>0.881731</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               texts  distance\n",
       "0  It has also received praise from many astronom...  0.617834\n",
       "1  Caltech theoretical physicist and 2017 Nobel l...  0.809877\n",
       "2  The father in the movie went to space to find ...  0.881731"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "search(\"how precise was the science\", number_of_results=3) # same as the original notebook."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using Langchain-chroma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_chroma import Chroma\n",
    "try:\n",
    "    chroma_client.delete_collection(name=\"example_collection\")\n",
    "except:\n",
    "    pass\n",
    "\n",
    "vector_store = Chroma(\n",
    "    collection_name=\"example_collection\",\n",
    "    embedding_function=embedding_model,\n",
    "    persist_directory=\"./chroma_langchain_db\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['0',\n",
       " '1',\n",
       " '2',\n",
       " '3',\n",
       " '4',\n",
       " '5',\n",
       " '6',\n",
       " '7',\n",
       " '8',\n",
       " '9',\n",
       " '10',\n",
       " '11',\n",
       " '12',\n",
       " '13',\n",
       " '14',\n",
       " '15',\n",
       " '16',\n",
       " '17']"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.documents import Document\n",
    "# document_1 = Document(\n",
    "#     page_content=\"I had chocolate chip pancakes and scrambled eggs for breakfast this morning.\",\n",
    "#     metadata={\"source\": \"tweet\"},\n",
    "#     id=1,\n",
    "# )\n",
    "documents = [Document(page_content=text) for text in texts]\n",
    "uuids = [str(id) for id in range(len(documents))]\n",
    "vector_store.add_documents(documents=documents, ids=uuids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(id='12', metadata={}, page_content='It has also received praise from many astronomers for its scientific accuracy and portrayal of theoretical astrophysics'),\n",
       " Document(id='4', metadata={}, page_content='Caltech theoretical physicist and 2017 Nobel laureate in Physics[4] Kip Thorne was an executive producer, acted as a scientific consultant, and wrote a tie-in book, The Science of Interstellar'),\n",
       " Document(id='15', metadata={}, page_content='The father in the movie went to space to find a new habitable planet for humanity')]"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results = vector_store.similarity_search(\"how precise was the science\", k=3)\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(Document(id='12', metadata={}, page_content='It has also received praise from many astronomers for its scientific accuracy and portrayal of theoretical astrophysics'),\n",
       "  0.6178344488143921),\n",
       " (Document(id='4', metadata={}, page_content='Caltech theoretical physicist and 2017 Nobel laureate in Physics[4] Kip Thorne was an executive producer, acted as a scientific consultant, and wrote a tie-in book, The Science of Interstellar'),\n",
       "  0.8098767995834351),\n",
       " (Document(id='15', metadata={}, page_content='The father in the movie went to space to find a new habitable planet for humanity'),\n",
       "  0.8817310333251953)]"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results = vector_store.similarity_search_with_score(\"how precise was the science\", k=3)\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(Document(id='12', metadata={}, page_content='It has also received praise from many astronomers for its scientific accuracy and portrayal of theoretical astrophysics'),\n",
       "  0.6178344488143921),\n",
       " (Document(id='4', metadata={}, page_content='Caltech theoretical physicist and 2017 Nobel laureate in Physics[4] Kip Thorne was an executive producer, acted as a scientific consultant, and wrote a tie-in book, The Science of Interstellar'),\n",
       "  0.8098767995834351),\n",
       " (Document(id='15', metadata={}, page_content='The father in the movie went to space to find a new habitable planet for humanity'),\n",
       "  0.8817310333251953)]"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results = vector_store.similarity_search_by_vector_with_relevance_scores(embedding=embedding_model.embed_query(\"how precise was the science\"), k=3)\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "def search_langchain(query, number_of_results=3):\n",
    "  # 1. Get the query's embedding\n",
    "  query_embed = embedding_model.embed_query(query)\n",
    "\n",
    "  # 2. Retrieve the nearest neighbors\n",
    "  search_result = vector_store.similarity_search_by_vector_with_relevance_scores(embedding=query_embed, k=number_of_results)\n",
    "\n",
    "  # 3. Format the results\n",
    "  results = pd.DataFrame(data={'texts': [doc[0].page_content for doc in search_result],\n",
    "                              'distance': [doc[1] for doc in search_result]})\n",
    "\n",
    "  # 4. Print and return the results\n",
    "  print(f\"Query:'{query}'\\nNearest neighbors:\")\n",
    "  return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query:'how precise was the science'\n",
      "Nearest neighbors:\n"
     ]
    },
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "texts",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "distance",
         "rawType": "float64",
         "type": "float"
        }
       ],
       "ref": "efe2c235-7d1d-457c-a5c5-0f9c61f19874",
       "rows": [
        [
         "0",
         "It has also received praise from many astronomers for its scientific accuracy and portrayal of theoretical astrophysics",
         "0.6178344488143921"
        ],
        [
         "1",
         "Caltech theoretical physicist and 2017 Nobel laureate in Physics[4] Kip Thorne was an executive producer, acted as a scientific consultant, and wrote a tie-in book, The Science of Interstellar",
         "0.8098767995834351"
        ],
        [
         "2",
         "The father in the movie went to space to find a new habitable planet for humanity",
         "0.8817310333251953"
        ]
       ],
       "shape": {
        "columns": 2,
        "rows": 3
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>texts</th>\n",
       "      <th>distance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>It has also received praise from many astronom...</td>\n",
       "      <td>0.617834</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Caltech theoretical physicist and 2017 Nobel l...</td>\n",
       "      <td>0.809877</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>The father in the movie went to space to find ...</td>\n",
       "      <td>0.881731</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               texts  distance\n",
       "0  It has also received praise from many astronom...  0.617834\n",
       "1  Caltech theoretical physicist and 2017 Nobel l...  0.809877\n",
       "2  The father in the movie went to space to find ...  0.881731"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "search_langchain(\"how precise was the science\", number_of_results=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "id": "EkkDh12ZGRhY"
   },
   "outputs": [],
   "source": [
    "from rank_bm25 import BM25Okapi\n",
    "from sklearn.feature_extraction import _stop_words\n",
    "import string\n",
    "\n",
    "def bm25_tokenizer(text):\n",
    "    tokenized_doc = []\n",
    "    for token in text.lower().split():\n",
    "        token = token.strip(string.punctuation)\n",
    "\n",
    "        if len(token) > 0 and token not in _stop_words.ENGLISH_STOP_WORDS:\n",
    "            tokenized_doc.append(token)\n",
    "    return tokenized_doc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 4,
     "status": "ok",
     "timestamp": 1718963358455,
     "user": {
      "displayName": "Maarten Grootendorst",
      "userId": "11015108362723620659"
     },
     "user_tz": -120
    },
    "id": "cHl8HnvgGXHG",
    "outputId": "0defa2a0-8e6b-436b-f6d2-6c5ce94f1636"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 18/18 [00:00<00:00, 99208.24it/s]\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "tokenized_corpus = []\n",
    "for passage in tqdm(texts):\n",
    "    tokenized_corpus.append(bm25_tokenizer(passage))\n",
    "\n",
    "bm25 = BM25Okapi(tokenized_corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "id": "ZlyGXye4GRj0"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "def keyword_search(query, top_k=3, num_candidates=15):\n",
    "    print(\"Input question:\", query)\n",
    "\n",
    "    ##### BM25 search (lexical search) #####\n",
    "    bm25_scores = bm25.get_scores(bm25_tokenizer(query))\n",
    "    top_n = np.argpartition(bm25_scores, -num_candidates)[-num_candidates:]\n",
    "    bm25_hits = [{'corpus_id': idx, 'score': bm25_scores[idx]} for idx in top_n]\n",
    "    bm25_hits = sorted(bm25_hits, key=lambda x: x['score'], reverse=True)\n",
    "\n",
    "    print(f\"Top-3 lexical search (BM25) hits\")\n",
    "    for hit in bm25_hits[0:top_k]:\n",
    "        print(\"\\t{:.3f}\\t{}\".format(hit['score'], texts[hit['corpus_id']].replace(\"\\n\", \" \")))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 3,
     "status": "ok",
     "timestamp": 1718963358455,
     "user": {
      "displayName": "Maarten Grootendorst",
      "userId": "11015108362723620659"
     },
     "user_tz": -120
    },
    "id": "jV-V_mhRGRmS",
    "outputId": "0957579e-0de7-4646-949e-cd9750178dcf"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input question: how precise was the science\n",
      "Top-3 lexical search (BM25) hits\n",
      "\t1.908\tInterstellar is a 2014 epic science fiction film co-written, directed, and produced by Christopher Nolan\n",
      "\t1.443\tCaltech theoretical physicist and 2017 Nobel laureate in Physics[4] Kip Thorne was an executive producer, acted as a scientific consultant, and wrote a tie-in book, The Science of Interstellar\n",
      "\t0.000\tCinematographer Hoyte van Hoytema shot it on 35 mm movie film in the Panavision anamorphic format and IMAX 70 mm\n"
     ]
    }
   ],
   "source": [
    "keyword_search(query = \"how precise was the science\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ehyhfd7NG5kw"
   },
   "source": [
    "## Caveats of Dense Retrieval\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 180
    },
    "executionInfo": {
     "elapsed": 280,
     "status": "ok",
     "timestamp": 1718963358733,
     "user": {
      "displayName": "Maarten Grootendorst",
      "userId": "11015108362723620659"
     },
     "user_tz": -120
    },
    "id": "NxYwEfYRGpNe",
    "outputId": "dfaf50a0-f500-4160-8126-1b3a825fe750"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query:'What is the mass of the moon?'\n",
      "Nearest neighbors:\n"
     ]
    },
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "texts",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "distance",
         "rawType": "float64",
         "type": "float"
        }
       ],
       "ref": "225fd4d8-657c-4ca8-b1a4-070474b7b130",
       "rows": [
        [
         "0",
         "It has also received praise from many astronomers for its scientific accuracy and portrayal of theoretical astrophysics",
         "0.9784406423568726"
        ],
        [
         "1",
         "Caltech theoretical physicist and 2017 Nobel laureate in Physics[4] Kip Thorne was an executive producer, acted as a scientific consultant, and wrote a tie-in book, The Science of Interstellar",
         "1.0317533016204834"
        ],
        [
         "2",
         "The father in the movie went to space to find a new habitable planet for humanity",
         "1.0608303546905518"
        ]
       ],
       "shape": {
        "columns": 2,
        "rows": 3
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>texts</th>\n",
       "      <th>distance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>It has also received praise from many astronom...</td>\n",
       "      <td>0.978441</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Caltech theoretical physicist and 2017 Nobel l...</td>\n",
       "      <td>1.031753</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>The father in the movie went to space to find ...</td>\n",
       "      <td>1.060830</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               texts  distance\n",
       "0  It has also received praise from many astronom...  0.978441\n",
       "1  Caltech theoretical physicist and 2017 Nobel l...  1.031753\n",
       "2  The father in the movie went to space to find ...  1.060830"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query = \"What is the mass of the moon?\"\n",
    "results = search(query)\n",
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "V_RalLmuG0jw"
   },
   "source": [
    "# Reranking Example\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Need to rewrite with open source models below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([  8.8459, -11.2456])\n",
      "tensor([[0],\n",
      "        [1]])\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoModelForSequenceClassification, AutoTokenizer\n",
    "import torch\n",
    "\n",
    "model = AutoModelForSequenceClassification.from_pretrained('cross-encoder/ms-marco-MiniLM-L6-v2')\n",
    "tokenizer = AutoTokenizer.from_pretrained('cross-encoder/ms-marco-MiniLM-L6-v2')\n",
    "\n",
    "features = tokenizer(['How many people live in Berlin?', 'How many people live in Berlin?'], ['Berlin has a population of 3,520,031 registered inhabitants in an area of 891.82 square kilometers.', 'New York City is famous for the Metropolitan Museum of Art.'],  padding=True, truncation=True, return_tensors=\"pt\")\n",
    "\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    scores = model(**features).logits\n",
    "    print(scores.flatten())\n",
    "    print(torch.argsort(scores, dim=0, descending=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "def search_with_reranking(query, number_of_results=3):\n",
    "    # 1. Retrieve the nearest neighbors\n",
    "    search_result = collection.query(query_texts=[query], n_results=number_of_results)\n",
    "\n",
    "    documents = search_result['documents'][0]\n",
    "    # Rerank the documents\n",
    "    features = tokenizer([query for _ in documents], documents,  padding=True, truncation=True, return_tensors=\"pt\")\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        scores = model(**features).logits\n",
    "    documents = [documents[i] for i in torch.argsort(scores, dim=0, descending=True).squeeze().tolist()]\n",
    "    distances = [search_result['distances'][0][i] for i in torch.argsort(scores, dim=0, descending=True).squeeze().tolist()]\n",
    "\n",
    "    # 2. Format the results\n",
    "    results = pd.DataFrame(data={'texts': documents,\n",
    "                                'distance': distances})\n",
    "\n",
    "    # 3. Print and return the results\n",
    "    print(f\"Query:'{query}'\\nNearest neighbors:\")\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 3,
     "status": "ok",
     "timestamp": 1718963358733,
     "user": {
      "displayName": "Maarten Grootendorst",
      "userId": "11015108362723620659"
     },
     "user_tz": -120
    },
    "id": "HulOxkW_Focv",
    "outputId": "06e05541-4383-452e-d41a-04c3dc5521fb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query:'how precise was the science'\n",
      "Nearest neighbors:\n"
     ]
    },
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "texts",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "distance",
         "rawType": "float64",
         "type": "float"
        }
       ],
       "ref": "ede924d4-7bdb-46ee-8f09-d939a4aaff13",
       "rows": [
        [
         "0",
         "It has also received praise from many astronomers for its scientific accuracy and portrayal of theoretical astrophysics",
         "0.6178344488143921"
        ],
        [
         "1",
         "Caltech theoretical physicist and 2017 Nobel laureate in Physics[4] Kip Thorne was an executive producer, acted as a scientific consultant, and wrote a tie-in book, The Science of Interstellar",
         "0.8098767995834351"
        ],
        [
         "2",
         "The father in the movie went to space to find a new habitable planet for humanity",
         "0.8817310333251953"
        ]
       ],
       "shape": {
        "columns": 2,
        "rows": 3
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>texts</th>\n",
       "      <th>distance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>It has also received praise from many astronom...</td>\n",
       "      <td>0.617834</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Caltech theoretical physicist and 2017 Nobel l...</td>\n",
       "      <td>0.809877</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>The father in the movie went to space to find ...</td>\n",
       "      <td>0.881731</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               texts  distance\n",
       "0  It has also received praise from many astronom...  0.617834\n",
       "1  Caltech theoretical physicist and 2017 Nobel l...  0.809877\n",
       "2  The father in the movie went to space to find ...  0.881731"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query = \"how precise was the science\"\n",
    "search_with_reranking(query=query, number_of_results=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "id": "rqYJaq2CFohv"
   },
   "outputs": [],
   "source": [
    "def keyword_and_reranking_search(query, top_k=3, num_candidates=10):\n",
    "    print(\"Input question:\", query)\n",
    "\n",
    "    ##### BM25 search (lexical search) #####\n",
    "    bm25_scores = bm25.get_scores(bm25_tokenizer(query))\n",
    "    top_n = np.argpartition(bm25_scores, -num_candidates)[-num_candidates:]\n",
    "    bm25_hits = [{'corpus_id': idx, 'score': bm25_scores[idx]} for idx in top_n]\n",
    "    bm25_hits = sorted(bm25_hits, key=lambda x: x['score'], reverse=True)\n",
    "\n",
    "    print(f\"Top-3 lexical search (BM25) hits\")\n",
    "    for hit in bm25_hits[0:top_k]:\n",
    "        print(\"\\t{:.3f}\\t{}\".format(hit['score'], texts[hit['corpus_id']].replace(\"\\n\", \" \")))\n",
    "\n",
    "    #Add re-ranking\n",
    "    docs = [texts[hit['corpus_id']] for hit in bm25_hits]\n",
    "\n",
    "    features = tokenizer([query for _ in docs], docs,  padding=True, truncation=True, return_tensors=\"pt\")\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        scores = model(**features).logits\n",
    "    bm25_hits_reranked = [bm25_hits[i] for i in torch.argsort(scores, dim=0, descending=True).squeeze().tolist()]\n",
    "\n",
    "    print(f\"\\nTop-3 hits by rank-API ({len(bm25_hits)} BM25 hits re-ranked)\")\n",
    "    for hit in bm25_hits_reranked[0:top_k]:\n",
    "        print(\"\\t{:.3f}\\t{}\".format(hit['score'], texts[hit['corpus_id']].replace(\"\\n\", \" \")))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1,
     "status": "ok",
     "timestamp": 1718963359073,
     "user": {
      "displayName": "Maarten Grootendorst",
      "userId": "11015108362723620659"
     },
     "user_tz": -120
    },
    "id": "9FITOXqkHONy",
    "outputId": "c4e81e12-b19c-4fa0-8ce6-7907002df7ca"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input question: location of filming\n",
      "Top-3 lexical search (BM25) hits\n",
      "\t0.000\tInterstellar premiered on October 26, 2014, in Los Angeles\n",
      "\t0.000\tIn the United States, it was first released on film stock, expanding to venues using digital projectors\n",
      "\t0.000\tThe film had a worldwide gross over $677 million (and $773 million with subsequent re-releases), making it the tenth-highest grossing film of 2014\n",
      "\n",
      "Top-3 hits by rank-API (10 BM25 hits re-ranked)\n",
      "\t0.000\tInterstellar premiered on October 26, 2014, in Los Angeles\n",
      "\t0.000\t\n",
      "\t0.000\tIn the United States, it was first released on film stock, expanding to venues using digital projectors\n"
     ]
    }
   ],
   "source": [
    "keyword_and_reranking_search(query = \"location of filming\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ugdnTs_VHV25"
   },
   "source": [
    "# Retrieval-Augmented Generation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-iqKQ7F0HZh-"
   },
   "source": [
    "## Example: Grounded Generation with an LLM API\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Not covered here, see OG notebook."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "D_25ztzEHuWX"
   },
   "source": [
    "## Example: RAG with Local Models\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jNZ5gUoWIYhp"
   },
   "source": [
    "### Loading the Generation Model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 33056,
     "status": "ok",
     "timestamp": 1718963395761,
     "user": {
      "displayName": "Maarten Grootendorst",
      "userId": "11015108362723620659"
     },
     "user_tz": -120
    },
    "id": "E4LNwOWTHvOv",
    "outputId": "945a6fa3-511d-48b7-d305-fe6d1dd23be9"
   },
   "outputs": [],
   "source": [
    "#!wget https://huggingface.co/microsoft/Phi-3-mini-4k-instruct-gguf/resolve/main/Phi-3-mini-4k-instruct-q4.gguf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "id": "a2Qgnc5OHvRQ"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "llama_context: n_batch is less than GGML_KQ_MASK_PAD - increasing to 64\n",
      "llama_context: n_ctx_per_seq (2048) < n_ctx_train (4096) -- the full capacity of the model will not be utilized\n"
     ]
    }
   ],
   "source": [
    "#from langchain import LlamaCpp # defecated\n",
    "from langchain_community.llms import LlamaCpp\n",
    "# Make sure the model path is correct for your system!\n",
    "llm = LlamaCpp(\n",
    "    model_path=\"Phi-3-mini-4k-instruct-q4.gguf\",\n",
    "    n_gpu_layers=-1,\n",
    "    max_tokens=500,\n",
    "    n_ctx=2048,\n",
    "    seed=42,\n",
    "    verbose=False\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "P06UYeIVIk1e"
   },
   "source": [
    "### The RAG Prompt\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "THESE ARE DEFECATED:\n",
    "* from langchain import PromptTemplate\n",
    "* from langchain.chains import RetrievalQA\n",
    "\n",
    "#### see https://python.langchain.com/docs/versions/migrating_chains/retrieval_qa/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "id": "F_3nTc69InwO"
   },
   "outputs": [],
   "source": [
    "from langchain import PromptTemplate\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "# Create a prompt template\n",
    "# must have {context} since below we pass context to it.\n",
    "template = \"\"\"<|user|>\n",
    "Relevant information:\n",
    "{context}\n",
    "\n",
    "Provide a concise answer the following question using the relevant information provided above:\n",
    "{question}<|end|>\n",
    "<|assistant|>\"\"\"\n",
    "prompt = PromptTemplate(\n",
    "    template=template,\n",
    "    input_variables=[\"context\", \"question\"]\n",
    ")\n",
    "\n",
    "def format_docs(docs):\n",
    "    return \"\\n\\n\".join(doc.page_content for doc in docs)\n",
    "\n",
    "\n",
    "qa_chain = (\n",
    "    {\n",
    "        \"context\": vector_store.as_retriever() | format_docs,\n",
    "        \"question\": RunnablePassthrough(),\n",
    "    }\n",
    "    | prompt\n",
    "    | llm\n",
    "    | StrOutputParser()\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note, no memory as we did not incorporate it. To have memory and be able to retrieve stuff, use retrieval as a tool instead of a pipeline.<br>\n",
    "See: https://langchain-ai.github.io/langgraph/tutorials/get-started/2-add-tools/#6-define-the-conditional_edges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 90250,
     "status": "ok",
     "timestamp": 1718963614201,
     "user": {
      "displayName": "Maarten Grootendorst",
      "userId": "11015108362723620659"
     },
     "user_tz": -120
    },
    "id": "x2p2pJPfIp16",
    "outputId": "3d284ce5-d35d-429d-fcec-a6a4a427dc05"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\" I'm Kelvin, and while the information provided doesn't directly relate to my personal details, it highlights Kip Thorne's significant contributions to theoretical astrophysics.\""
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "qa_chain.invoke('My name is Kelvin.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' The movie generated over $677 million worldwide, with a total of $773 million after subsequent re-releases.'"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "qa_chain.invoke('How much monetary value was generated from this movie?')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' The information provided does not include the name of a person. It mentions Christopher and Jonathan Nolan, Kip Thorne, but none of them are referred to as \"I\". Therefore, it\\'s impossible to deduce your name from the given context.'"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "qa_chain.invoke('What is my name again?')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### More verbose version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input': 'How much monetary value was generated from this movie?',\n",
       " 'context': [Document(id='10', metadata={}, page_content='The film had a worldwide gross over $677 million (and $773 million with subsequent re-releases), making it the tenth-highest grossing film of 2014'),\n",
       "  Document(id='11', metadata={}, page_content='It received acclaim for its performances, direction, screenplay, musical score, visual effects, ambition, themes, and emotional weight'),\n",
       "  Document(id='5', metadata={}, page_content='Cinematographer Hoyte van Hoytema shot it on 35 mm movie film in the Panavision anamorphic format and IMAX 70 mm'),\n",
       "  Document(id='15', metadata={}, page_content='The father in the movie went to space to find a new habitable planet for humanity')],\n",
       " 'answer': ' The movie generated over $677 million worldwide, with a total of $773 million after subsequent re-releases.'}"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.chains import create_retrieval_chain\n",
    "from langchain.chains.combine_documents import create_stuff_documents_chain\n",
    "# must have {context} and {input}.\n",
    "template = \"\"\"<|user|>\n",
    "Relevant information:\n",
    "{context}\n",
    "\n",
    "Provide a concise answer the following question using the relevant information provided above:\n",
    "{input}<|end|>\n",
    "<|assistant|>\"\"\"\n",
    "prompt = PromptTemplate(\n",
    "    template=template,\n",
    "    input_variables=[\"context\", \"input\"]\n",
    ")\n",
    "combine_docs_chain = create_stuff_documents_chain(llm, prompt=prompt)\n",
    "rag_chain = create_retrieval_chain(vector_store.as_retriever(), combine_docs_chain)\n",
    "\n",
    "rag_chain.invoke({\"input\": \"How much monetary value was generated from this movie?\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **NOTE:** Recall the current RAG setup is \n",
    "1) retrieval first (e.g. dense retrieval)\n",
    "2) LLM read contents and generate.\n",
    "\n",
    "In the book, sometimes when the search query is too verbose, we may not retrieve relevant enough documents in step 1).<br>For example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\" Unfortunately, the provided information does not include specific details about the movie Interstellar's box office earnings or total revenue. However, it is known that since its premiere, Interstellar has gained a cult following and was nominated for five awards at the 87th Academy Awards, including Best Visual Effects. For precise financial data, you might want to consult external sources such as Box Office Mojo or industry reports.\""
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query = \"\"\"\n",
    "We have an essay due tomorrow. We have to write about some facts about the movie Interstellar.\n",
    "I love talking about money. I could write about them. But I could also write about the science.\n",
    "Maybe. Let's do money. How much money did the movie generate?\n",
    "\"\"\"\n",
    "qa_chain.invoke(query)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To solve this, it is a good idea to use an LLM to rewrite the query into one that aids the retrieval step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "llama_context: n_batch is less than GGML_KQ_MASK_PAD - increasing to 64\n",
      "llama_context: n_ctx_per_seq (2048) < n_ctx_train (4096) -- the full capacity of the model will not be utilized\n"
     ]
    }
   ],
   "source": [
    "llm_summarizer = LlamaCpp(\n",
    "    model_path=\"Phi-3-mini-4k-instruct-q4.gguf\",\n",
    "    n_gpu_layers=-1,\n",
    "    max_tokens=500,\n",
    "    n_ctx=2048,\n",
    "    seed=42,\n",
    "    verbose=False\n",
    ")\n",
    "template = \"\"\"<|user|>\n",
    "Your task is to extract the relevant information from the question below to use as a search query:\n",
    "{question}<|end|>\n",
    "<|assistant|>\"\"\"\n",
    "question_prompt = PromptTemplate(\n",
    "    template=template,\n",
    "    input_variables=[\"question\"]\n",
    ")\n",
    "\n",
    "def print_query(query):\n",
    "    print(\"Original question:\", query)\n",
    "    concise_query = question_prompt.format(question=query)\n",
    "    print(\"Concise query for search:\", llm_summarizer.predict(concise_query))\n",
    "    return query\n",
    "\n",
    "summarization_chain = (\n",
    "    question_prompt\n",
    "    | llm_summarizer | print_query\n",
    "    | {\"context\": vector_store.as_retriever() | format_docs, \"input\": RunnablePassthrough()}\n",
    "    | prompt\n",
    "    | llm\n",
    "    | StrOutputParser()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original question:  search query: \"Interstellar movie financial data - box office earnings\"\n",
      "Concise query for search:  search query: \"Interstellar box office earnings financial data\"\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\" I'm sorry, but the information provided doesn't include specific details about Interstellar's box office earnings. For this data, you might want to consult financial databases or film industry reports that track a movie's performance post its release date.\""
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query = \"\"\"\n",
    "We have an essay due tomorrow. We have to write about some facts about the movie Interstellar.\n",
    "I love talking about money. I could write about them. But I could also write about the science.\n",
    "Maybe. Let's do money. How much money did the movie generate?\n",
    "\"\"\"\n",
    "summarization_chain.invoke(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' The provided information does not include specific details about the box office revenue or earnings of \"Interstellar.\"'"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "qa_chain.invoke('\"Interstellar\" box office revenue, earnings')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input': 'Interstellar money generated',\n",
       " 'context': [Document(id='7', metadata={}, page_content='Interstellar uses extensive practical and miniature effects and the company Double Negative created additional digital effects'),\n",
       "  Document(id='8', metadata={}, page_content='Interstellar premiered on October 26, 2014, in Los Angeles'),\n",
       "  Document(id='0', metadata={}, page_content='Interstellar is a 2014 epic science fiction film co-written, directed, and produced by Christopher Nolan'),\n",
       "  Document(id='13', metadata={}, page_content='Since its premiere, Interstellar gained a cult following,[5] and now is regarded by many sci-fi experts as one of the best science-fiction films of all time')],\n",
       " 'answer': ' The information provided does not include specific details about the financial earnings of Interstellar. However, it is a highly acclaimed sci-fi film directed by Christopher Nolan and has gained a cult following since its 2014 premiere in Los Angeles. For accurate box office data, you may refer to industry reports or databases that track movie revenues.'}"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rag_chain.invoke({\"input\":'Interstellar money generated'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input': 'money generated',\n",
       " 'context': [Document(id='17', metadata={}, page_content=''),\n",
       "  Document(id='9', metadata={}, page_content='In the United States, it was first released on film stock, expanding to venues using digital projectors'),\n",
       "  Document(id='7', metadata={}, page_content='Interstellar uses extensive practical and miniature effects and the company Double Negative created additional digital effects'),\n",
       "  Document(id='10', metadata={}, page_content='The film had a worldwide gross over $677 million (and $773 million with subsequent re-releases), making it the tenth-highest grossing film of 2014')],\n",
       " 'answer': ' Interstellar, released in the United States and globally using various projection methods, generated over $677 million worldwide at its initial release. With subsequent re-releases, it grossed a total of $773 million.'}"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rag_chain.invoke({\"input\":'money generated'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original question:  search query: \"movie financial data generated revenue\"\n",
      "Concise query for search:  \"movie financial data revenue generation\"\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "' I\\'m sorry, but the provided information does not directly relate to financial data or revenue generated by \"Interstellar.\" However, for general movie financial details, one might look into box office earnings or production budgets. If you are interested in these aspects of \"Interstellar,\" please let me know so I can assist further with that query.'"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query = \"\"\"\n",
    "We have an essay due tomorrow. We have to write about some facts about the movie.\n",
    "I love talking about money. I could write about them. But I could also write about the science.\n",
    "Maybe. Let's do money. How much money did the movie generate?\n",
    "\"\"\"\n",
    "summarization_chain.invoke(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original question:  search_query: \"final location of the father in [source context]\"\n",
      "Concise query for search:  search_query: \"father's final location in [source context provided]\"\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "' The final location of the father in the movie, as per the provided context, is not explicitly mentioned. However, since he got stranded in a different dimension after leaving Earth for space to find a new habitable planet, it can be inferred that his last known \"location\" would technically be somewhere beyond our understanding or within this alternate dimension rather than on any specific geographical location like Alberta, Iceland, or Los Angeles.'"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query = \"\"\"\n",
    "Where did the father end up?\n",
    "\"\"\"\n",
    "summarization_chain.invoke(query)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
