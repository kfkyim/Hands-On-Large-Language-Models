{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_A2SZPmbD4Pk"
   },
   "source": [
    "<h1>Chapter 8 - Semantic Search and Retrieval-Augmented Generation</h1>\n",
    "<i>Exploring a vital part of LLMs, search.</i>\n",
    "\n",
    "<a href=\"https://www.amazon.com/Hands-Large-Language-Models-Understanding/dp/1098150961\"><img src=\"https://img.shields.io/badge/Buy%20the%20Book!-grey?logo=amazon\"></a>\n",
    "<a href=\"https://www.oreilly.com/library/view/hands-on-large-language/9781098150952/\"><img src=\"https://img.shields.io/badge/O'Reilly-white.svg?logo=data:image/svg%2bxml;base64,PHN2ZyB3aWR0aD0iMzQiIGhlaWdodD0iMjciIHZpZXdCb3g9IjAgMCAzNCAyNyIgZmlsbD0ibm9uZSIgeG1sbnM9Imh0dHA6Ly93d3cudzMub3JnLzIwMDAvc3ZnIj4KPGNpcmNsZSBjeD0iMTMiIGN5PSIxNCIgcj0iMTEiIHN0cm9rZT0iI0Q0MDEwMSIgc3Ryb2tlLXdpZHRoPSI0Ii8+CjxjaXJjbGUgY3g9IjMwLjUiIGN5PSIzLjUiIHI9IjMuNSIgZmlsbD0iI0Q0MDEwMSIvPgo8L3N2Zz4K\"></a>\n",
    "<a href=\"https://github.com/HandsOnLLM/Hands-On-Large-Language-Models\"><img src=\"https://img.shields.io/badge/GitHub%20Repository-black?logo=github\"></a>\n",
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/HandsOnLLM/Hands-On-Large-Language-Models/blob/main/chapter08/Chapter%208%20-%20Semantic%20Search.ipynb)\n",
    "\n",
    "---\n",
    "\n",
    "This notebook is for Chapter 8 of the [Hands-On Large Language Models](https://www.amazon.com/Hands-Large-Language-Models-Understanding/dp/1098150961) book by [Jay Alammar](https://www.linkedin.com/in/jalammar) and [Maarten Grootendorst](https://www.linkedin.com/in/mgrootendorst/).\n",
    "\n",
    "---\n",
    "\n",
    "<a href=\"https://www.amazon.com/Hands-Large-Language-Models-Understanding/dp/1098150961\">\n",
    "<img src=\"https://raw.githubusercontent.com/HandsOnLLM/Hands-On-Large-Language-Models/main/images/book_cover.png\" width=\"350\"/></a>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [OPTIONAL] - Installing Packages on <img src=\"https://colab.google/static/images/icons/colab.png\" width=100>\n",
    "\n",
    "If you are viewing this notebook on Google Colab (or any other cloud vendor), you need to **uncomment and run** the following codeblock to install the dependencies for this chapter:\n",
    "\n",
    "---\n",
    "\n",
    "ðŸ’¡ **NOTE**: We will want to use a GPU to run the examples in this notebook. In Google Colab, go to\n",
    "**Runtime > Change runtime type > Hardware accelerator > GPU > GPU type > T4**.\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%capture\n",
    "# !pip install langchain==0.2.5 faiss-cpu==1.8.0 cohere==5.5.8 langchain-community==0.2.5 rank_bm25==0.2.2 sentence-transformers==3.0.1\n",
    "# !pip install llama-cpp-python==0.2.78  --extra-index-url https://abetlen.github.io/llama-cpp-python/whl/cu124\n",
    "\n",
    "## IMPORTANT: Make sure to restart the session after installing the packages above."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ye0HbBr3EV0P"
   },
   "source": [
    "# Dense Retrieval Example\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Svgdo3y3F741"
   },
   "source": [
    "## 1. Getting the text archive and chunking it\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "_Dcq1j_xFxIr"
   },
   "outputs": [],
   "source": [
    "text = \"\"\"\n",
    "Interstellar is a 2014 epic science fiction film co-written, directed, and produced by Christopher Nolan.\n",
    "It stars Matthew McConaughey, Anne Hathaway, Jessica Chastain, Bill Irwin, Ellen Burstyn, Matt Damon, and Michael Caine.\n",
    "Set in a dystopian future where humanity is struggling to survive, the film follows a group of astronauts who travel through a wormhole near Saturn in search of a new home for mankind.\n",
    "\n",
    "Brothers Christopher and Jonathan Nolan wrote the screenplay, which had its origins in a script Jonathan developed in 2007.\n",
    "Caltech theoretical physicist and 2017 Nobel laureate in Physics[4] Kip Thorne was an executive producer, acted as a scientific consultant, and wrote a tie-in book, The Science of Interstellar.\n",
    "Cinematographer Hoyte van Hoytema shot it on 35 mm movie film in the Panavision anamorphic format and IMAX 70 mm.\n",
    "Principal photography began in late 2013 and took place in Alberta, Iceland, and Los Angeles.\n",
    "Interstellar uses extensive practical and miniature effects and the company Double Negative created additional digital effects.\n",
    "\n",
    "Interstellar premiered on October 26, 2014, in Los Angeles.\n",
    "In the United States, it was first released on film stock, expanding to venues using digital projectors.\n",
    "The film had a worldwide gross over $677 million (and $773 million with subsequent re-releases), making it the tenth-highest grossing film of 2014.\n",
    "It received acclaim for its performances, direction, screenplay, musical score, visual effects, ambition, themes, and emotional weight.\n",
    "It has also received praise from many astronomers for its scientific accuracy and portrayal of theoretical astrophysics. Since its premiere, Interstellar gained a cult following,[5] and now is regarded by many sci-fi experts as one of the best science-fiction films of all time.\n",
    "Interstellar was nominated for five awards at the 87th Academy Awards, winning Best Visual Effects, and received numerous other accolades\"\"\"\n",
    "\n",
    "# Split into a list of sentences\n",
    "texts = text.split('.')\n",
    "\n",
    "# Clean up to remove empty spaces and new lines\n",
    "texts = [t.strip(' \\n') for t in texts]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "krDDOpcZF5qo"
   },
   "source": [
    "## 2. Embedding the Text Chunks, Creating Vector DB, Add and Query Data\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\USER\\Desktop\\Neural Networks Repo\\.venv\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from langchain_huggingface import HuggingFaceEmbeddings\n",
    "from tqdm import tqdm\n",
    "\n",
    "embedding_model = HuggingFaceEmbeddings(\n",
    "    model_name='BAAI/bge-small-en-v1.5'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using Chroma's native API (will use LangChain Version after)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\USER\\AppData\\Local\\Temp\\ipykernel_104728\\624235270.py:9: DeprecationWarning: The class MyEmbeddingFunction does not implement __init__. This will be required in a future version.\n",
      "  embedding_function = MyEmbeddingFunction()\n"
     ]
    }
   ],
   "source": [
    "import chromadb\n",
    "from chromadb import Documents, EmbeddingFunction, Embeddings\n",
    "\n",
    "class MyEmbeddingFunction(EmbeddingFunction):\n",
    "    def __call__(self, input: Documents) -> Embeddings:\n",
    "        embeddings = embedding_model.embed_documents(input)\n",
    "        return embeddings\n",
    "    \n",
    "embedding_function = MyEmbeddingFunction()\n",
    "\n",
    "chroma_client = chromadb.PersistentClient(path=\"./chroma_db\")\n",
    "try:\n",
    "    chroma_client.delete_collection(name=\"my_collection\")\n",
    "except:\n",
    "    pass\n",
    "collection = chroma_client.create_collection(\n",
    "    name=\"my_collection\",\n",
    "    embedding_function=embedding_function\n",
    ")\n",
    "collection.add(\n",
    "    ids=[str(id) for id in range(len(texts))], \n",
    "    documents=texts\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "15"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(embedding_function(texts))  # should be 15"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ids': [['12', '4', '7']],\n",
       " 'embeddings': None,\n",
       " 'documents': [['It has also received praise from many astronomers for its scientific accuracy and portrayal of theoretical astrophysics',\n",
       "   'Caltech theoretical physicist and 2017 Nobel laureate in Physics[4] Kip Thorne was an executive producer, acted as a scientific consultant, and wrote a tie-in book, The Science of Interstellar',\n",
       "   'Interstellar uses extensive practical and miniature effects and the company Double Negative created additional digital effects']],\n",
       " 'uris': None,\n",
       " 'included': ['metadatas', 'documents', 'distances'],\n",
       " 'data': None,\n",
       " 'metadatas': [[None, None, None]],\n",
       " 'distances': [[0.6178343892097473, 0.8098766803741455, 0.9237760901451111]]}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# cannot handle too verbose of a query yet. need intermediate LLM to change query to more concise version later. Use concise query for now.\n",
    "collection.query(query_texts='how precise was the science', n_results=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "def search(query, number_of_results=3):\n",
    "  # 1. Get the query's embedding\n",
    "  query_embed = embedding_function([query])[0]\n",
    "\n",
    "  # 2. Retrieve the nearest neighbors\n",
    "  search_result = collection.query(query_texts=[query], n_results=number_of_results)\n",
    "\n",
    "  # 3. Format the results\n",
    "  results = pd.DataFrame(data={'texts': search_result['documents'][0],\n",
    "                              'distance': search_result['distances'][0]})\n",
    "\n",
    "  # 4. Print and return the results\n",
    "  print(f\"Query:'{query}'\\nNearest neighbors:\")\n",
    "  return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query:'how precise was the science'\n",
      "Nearest neighbors:\n"
     ]
    },
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "texts",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "distance",
         "rawType": "float64",
         "type": "float"
        }
       ],
       "ref": "abf6ce9c-a4cc-40d9-b99f-4b4c81b5f5ae",
       "rows": [
        [
         "0",
         "It has also received praise from many astronomers for its scientific accuracy and portrayal of theoretical astrophysics",
         "0.6178343892097473"
        ],
        [
         "1",
         "Caltech theoretical physicist and 2017 Nobel laureate in Physics[4] Kip Thorne was an executive producer, acted as a scientific consultant, and wrote a tie-in book, The Science of Interstellar",
         "0.8098766803741455"
        ],
        [
         "2",
         "Interstellar uses extensive practical and miniature effects and the company Double Negative created additional digital effects",
         "0.9237760901451111"
        ]
       ],
       "shape": {
        "columns": 2,
        "rows": 3
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>texts</th>\n",
       "      <th>distance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>It has also received praise from many astronom...</td>\n",
       "      <td>0.617834</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Caltech theoretical physicist and 2017 Nobel l...</td>\n",
       "      <td>0.809877</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Interstellar uses extensive practical and mini...</td>\n",
       "      <td>0.923776</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               texts  distance\n",
       "0  It has also received praise from many astronom...  0.617834\n",
       "1  Caltech theoretical physicist and 2017 Nobel l...  0.809877\n",
       "2  Interstellar uses extensive practical and mini...  0.923776"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "search(\"how precise was the science\", number_of_results=3) # same as the original notebook."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using Langchain-chroma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_chroma import Chroma\n",
    "try:\n",
    "    chroma_client.delete_collection(name=\"example_collection\")\n",
    "except:\n",
    "    pass\n",
    "\n",
    "vector_store = Chroma(\n",
    "    collection_name=\"example_collection\",\n",
    "    embedding_function=embedding_model,\n",
    "    persist_directory=\"./chroma_langchain_db\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['0',\n",
       " '1',\n",
       " '2',\n",
       " '3',\n",
       " '4',\n",
       " '5',\n",
       " '6',\n",
       " '7',\n",
       " '8',\n",
       " '9',\n",
       " '10',\n",
       " '11',\n",
       " '12',\n",
       " '13',\n",
       " '14']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.documents import Document\n",
    "# document_1 = Document(\n",
    "#     page_content=\"I had chocolate chip pancakes and scrambled eggs for breakfast this morning.\",\n",
    "#     metadata={\"source\": \"tweet\"},\n",
    "#     id=1,\n",
    "# )\n",
    "documents = [Document(page_content=text) for text in texts]\n",
    "uuids = [str(id) for id in range(len(documents))]\n",
    "vector_store.add_documents(documents=documents, ids=uuids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(id='12', metadata={}, page_content='It has also received praise from many astronomers for its scientific accuracy and portrayal of theoretical astrophysics'),\n",
       " Document(id='4', metadata={}, page_content='Caltech theoretical physicist and 2017 Nobel laureate in Physics[4] Kip Thorne was an executive producer, acted as a scientific consultant, and wrote a tie-in book, The Science of Interstellar'),\n",
       " Document(id='7', metadata={}, page_content='Interstellar uses extensive practical and miniature effects and the company Double Negative created additional digital effects')]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results = vector_store.similarity_search(\"how precise was the science\", k=3)\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(Document(id='12', metadata={}, page_content='It has also received praise from many astronomers for its scientific accuracy and portrayal of theoretical astrophysics'),\n",
       "  0.6178343892097473),\n",
       " (Document(id='4', metadata={}, page_content='Caltech theoretical physicist and 2017 Nobel laureate in Physics[4] Kip Thorne was an executive producer, acted as a scientific consultant, and wrote a tie-in book, The Science of Interstellar'),\n",
       "  0.8098766803741455),\n",
       " (Document(id='7', metadata={}, page_content='Interstellar uses extensive practical and miniature effects and the company Double Negative created additional digital effects'),\n",
       "  0.9237760901451111)]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results = vector_store.similarity_search_with_score(\"how precise was the science\", k=3)\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(Document(id='12', metadata={}, page_content='It has also received praise from many astronomers for its scientific accuracy and portrayal of theoretical astrophysics'),\n",
       "  0.6178343892097473),\n",
       " (Document(id='4', metadata={}, page_content='Caltech theoretical physicist and 2017 Nobel laureate in Physics[4] Kip Thorne was an executive producer, acted as a scientific consultant, and wrote a tie-in book, The Science of Interstellar'),\n",
       "  0.8098766803741455),\n",
       " (Document(id='7', metadata={}, page_content='Interstellar uses extensive practical and miniature effects and the company Double Negative created additional digital effects'),\n",
       "  0.9237760901451111)]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results = vector_store.similarity_search_by_vector_with_relevance_scores(embedding=embedding_model.embed_query(\"how precise was the science\"), k=3)\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "def search_langchain(query, number_of_results=3):\n",
    "  # 1. Get the query's embedding\n",
    "  query_embed = embedding_model.embed_query(query)\n",
    "\n",
    "  # 2. Retrieve the nearest neighbors\n",
    "  search_result = vector_store.similarity_search_by_vector_with_relevance_scores(embedding=query_embed, k=number_of_results)\n",
    "\n",
    "  # 3. Format the results\n",
    "  results = pd.DataFrame(data={'texts': [doc[0].page_content for doc in search_result],\n",
    "                              'distance': [doc[1] for doc in search_result]})\n",
    "\n",
    "  # 4. Print and return the results\n",
    "  print(f\"Query:'{query}'\\nNearest neighbors:\")\n",
    "  return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query:'how precise was the science'\n",
      "Nearest neighbors:\n"
     ]
    },
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "texts",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "distance",
         "rawType": "float64",
         "type": "float"
        }
       ],
       "ref": "d894f7bd-a758-4242-b85c-5014ca28783a",
       "rows": [
        [
         "0",
         "It has also received praise from many astronomers for its scientific accuracy and portrayal of theoretical astrophysics",
         "0.6178343892097473"
        ],
        [
         "1",
         "Caltech theoretical physicist and 2017 Nobel laureate in Physics[4] Kip Thorne was an executive producer, acted as a scientific consultant, and wrote a tie-in book, The Science of Interstellar",
         "0.8098766803741455"
        ],
        [
         "2",
         "Interstellar uses extensive practical and miniature effects and the company Double Negative created additional digital effects",
         "0.9237760901451111"
        ]
       ],
       "shape": {
        "columns": 2,
        "rows": 3
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>texts</th>\n",
       "      <th>distance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>It has also received praise from many astronom...</td>\n",
       "      <td>0.617834</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Caltech theoretical physicist and 2017 Nobel l...</td>\n",
       "      <td>0.809877</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Interstellar uses extensive practical and mini...</td>\n",
       "      <td>0.923776</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               texts  distance\n",
       "0  It has also received praise from many astronom...  0.617834\n",
       "1  Caltech theoretical physicist and 2017 Nobel l...  0.809877\n",
       "2  Interstellar uses extensive practical and mini...  0.923776"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "search_langchain(\"how precise was the science\", number_of_results=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "EkkDh12ZGRhY"
   },
   "outputs": [],
   "source": [
    "from rank_bm25 import BM25Okapi\n",
    "from sklearn.feature_extraction import _stop_words\n",
    "import string\n",
    "\n",
    "def bm25_tokenizer(text):\n",
    "    tokenized_doc = []\n",
    "    for token in text.lower().split():\n",
    "        token = token.strip(string.punctuation)\n",
    "\n",
    "        if len(token) > 0 and token not in _stop_words.ENGLISH_STOP_WORDS:\n",
    "            tokenized_doc.append(token)\n",
    "    return tokenized_doc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 4,
     "status": "ok",
     "timestamp": 1718963358455,
     "user": {
      "displayName": "Maarten Grootendorst",
      "userId": "11015108362723620659"
     },
     "user_tz": -120
    },
    "id": "cHl8HnvgGXHG",
    "outputId": "0defa2a0-8e6b-436b-f6d2-6c5ce94f1636"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 15/15 [00:00<00:00, 75527.68it/s]\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "tokenized_corpus = []\n",
    "for passage in tqdm(texts):\n",
    "    tokenized_corpus.append(bm25_tokenizer(passage))\n",
    "\n",
    "bm25 = BM25Okapi(tokenized_corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "ZlyGXye4GRj0"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "def keyword_search(query, top_k=3, num_candidates=15):\n",
    "    print(\"Input question:\", query)\n",
    "\n",
    "    ##### BM25 search (lexical search) #####\n",
    "    bm25_scores = bm25.get_scores(bm25_tokenizer(query))\n",
    "    top_n = np.argpartition(bm25_scores, -num_candidates)[-num_candidates:]\n",
    "    bm25_hits = [{'corpus_id': idx, 'score': bm25_scores[idx]} for idx in top_n]\n",
    "    bm25_hits = sorted(bm25_hits, key=lambda x: x['score'], reverse=True)\n",
    "\n",
    "    print(f\"Top-3 lexical search (BM25) hits\")\n",
    "    for hit in bm25_hits[0:top_k]:\n",
    "        print(\"\\t{:.3f}\\t{}\".format(hit['score'], texts[hit['corpus_id']].replace(\"\\n\", \" \")))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 3,
     "status": "ok",
     "timestamp": 1718963358455,
     "user": {
      "displayName": "Maarten Grootendorst",
      "userId": "11015108362723620659"
     },
     "user_tz": -120
    },
    "id": "jV-V_mhRGRmS",
    "outputId": "0957579e-0de7-4646-949e-cd9750178dcf"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input question: how precise was the science\n",
      "Top-3 lexical search (BM25) hits\n",
      "\t1.789\tInterstellar is a 2014 epic science fiction film co-written, directed, and produced by Christopher Nolan\n",
      "\t1.373\tCaltech theoretical physicist and 2017 Nobel laureate in Physics[4] Kip Thorne was an executive producer, acted as a scientific consultant, and wrote a tie-in book, The Science of Interstellar\n",
      "\t0.000\tIt stars Matthew McConaughey, Anne Hathaway, Jessica Chastain, Bill Irwin, Ellen Burstyn, Matt Damon, and Michael Caine\n"
     ]
    }
   ],
   "source": [
    "keyword_search(query = \"how precise was the science\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ehyhfd7NG5kw"
   },
   "source": [
    "## Caveats of Dense Retrieval\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 180
    },
    "executionInfo": {
     "elapsed": 280,
     "status": "ok",
     "timestamp": 1718963358733,
     "user": {
      "displayName": "Maarten Grootendorst",
      "userId": "11015108362723620659"
     },
     "user_tz": -120
    },
    "id": "NxYwEfYRGpNe",
    "outputId": "dfaf50a0-f500-4160-8126-1b3a825fe750"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query:'What is the mass of the moon?'\n",
      "Nearest neighbors:\n"
     ]
    },
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "texts",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "distance",
         "rawType": "float64",
         "type": "float"
        }
       ],
       "ref": "83ba85e8-630a-4c04-a183-538da6e5fd31",
       "rows": [
        [
         "0",
         "It has also received praise from many astronomers for its scientific accuracy and portrayal of theoretical astrophysics",
         "0.9784404039382935"
        ],
        [
         "1",
         "Caltech theoretical physicist and 2017 Nobel laureate in Physics[4] Kip Thorne was an executive producer, acted as a scientific consultant, and wrote a tie-in book, The Science of Interstellar",
         "1.0317533016204834"
        ],
        [
         "2",
         "Interstellar premiered on October 26, 2014, in Los Angeles",
         "1.1206178665161133"
        ]
       ],
       "shape": {
        "columns": 2,
        "rows": 3
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>texts</th>\n",
       "      <th>distance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>It has also received praise from many astronom...</td>\n",
       "      <td>0.978440</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Caltech theoretical physicist and 2017 Nobel l...</td>\n",
       "      <td>1.031753</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Interstellar premiered on October 26, 2014, in...</td>\n",
       "      <td>1.120618</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               texts  distance\n",
       "0  It has also received praise from many astronom...  0.978440\n",
       "1  Caltech theoretical physicist and 2017 Nobel l...  1.031753\n",
       "2  Interstellar premiered on October 26, 2014, in...  1.120618"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query = \"What is the mass of the moon?\"\n",
    "results = search(query)\n",
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "V_RalLmuG0jw"
   },
   "source": [
    "# Reranking Example\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Need to rewrite with open source models below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([  8.8459, -11.2456])\n",
      "tensor([[0],\n",
      "        [1]])\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoModelForSequenceClassification, AutoTokenizer\n",
    "import torch\n",
    "\n",
    "model = AutoModelForSequenceClassification.from_pretrained('cross-encoder/ms-marco-MiniLM-L6-v2')\n",
    "tokenizer = AutoTokenizer.from_pretrained('cross-encoder/ms-marco-MiniLM-L6-v2')\n",
    "\n",
    "features = tokenizer(['How many people live in Berlin?', 'How many people live in Berlin?'], ['Berlin has a population of 3,520,031 registered inhabitants in an area of 891.82 square kilometers.', 'New York City is famous for the Metropolitan Museum of Art.'],  padding=True, truncation=True, return_tensors=\"pt\")\n",
    "\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    scores = model(**features).logits\n",
    "    print(scores.flatten())\n",
    "    print(torch.argsort(scores, dim=0, descending=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "def search_with_reranking(query, number_of_results=3):\n",
    "    # 1. Retrieve the nearest neighbors\n",
    "    search_result = collection.query(query_texts=[query], n_results=number_of_results)\n",
    "\n",
    "    documents = search_result['documents'][0]\n",
    "    # Rerank the documents\n",
    "    features = tokenizer([query for _ in documents], documents,  padding=True, truncation=True, return_tensors=\"pt\")\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        scores = model(**features).logits\n",
    "    documents = [documents[i] for i in torch.argsort(scores, dim=0, descending=True).squeeze().tolist()]\n",
    "    distances = [search_result['distances'][0][i] for i in torch.argsort(scores, dim=0, descending=True).squeeze().tolist()]\n",
    "\n",
    "    # 2. Format the results\n",
    "    results = pd.DataFrame(data={'texts': documents,\n",
    "                                'distance': distances})\n",
    "\n",
    "    # 3. Print and return the results\n",
    "    print(f\"Query:'{query}'\\nNearest neighbors:\")\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 3,
     "status": "ok",
     "timestamp": 1718963358733,
     "user": {
      "displayName": "Maarten Grootendorst",
      "userId": "11015108362723620659"
     },
     "user_tz": -120
    },
    "id": "HulOxkW_Focv",
    "outputId": "06e05541-4383-452e-d41a-04c3dc5521fb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query:'how precise was the science'\n",
      "Nearest neighbors:\n"
     ]
    },
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "texts",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "distance",
         "rawType": "float64",
         "type": "float"
        }
       ],
       "ref": "1dd62f65-6843-4f37-b019-51fdcde6fb56",
       "rows": [
        [
         "0",
         "It has also received praise from many astronomers for its scientific accuracy and portrayal of theoretical astrophysics",
         "0.6178343892097473"
        ],
        [
         "1",
         "Caltech theoretical physicist and 2017 Nobel laureate in Physics[4] Kip Thorne was an executive producer, acted as a scientific consultant, and wrote a tie-in book, The Science of Interstellar",
         "0.8098766803741455"
        ],
        [
         "2",
         "Interstellar uses extensive practical and miniature effects and the company Double Negative created additional digital effects",
         "0.9237760901451111"
        ]
       ],
       "shape": {
        "columns": 2,
        "rows": 3
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>texts</th>\n",
       "      <th>distance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>It has also received praise from many astronom...</td>\n",
       "      <td>0.617834</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Caltech theoretical physicist and 2017 Nobel l...</td>\n",
       "      <td>0.809877</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Interstellar uses extensive practical and mini...</td>\n",
       "      <td>0.923776</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               texts  distance\n",
       "0  It has also received praise from many astronom...  0.617834\n",
       "1  Caltech theoretical physicist and 2017 Nobel l...  0.809877\n",
       "2  Interstellar uses extensive practical and mini...  0.923776"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query = \"how precise was the science\"\n",
    "search_with_reranking(query=query, number_of_results=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "id": "rqYJaq2CFohv"
   },
   "outputs": [],
   "source": [
    "def keyword_and_reranking_search(query, top_k=3, num_candidates=10):\n",
    "    print(\"Input question:\", query)\n",
    "\n",
    "    ##### BM25 search (lexical search) #####\n",
    "    bm25_scores = bm25.get_scores(bm25_tokenizer(query))\n",
    "    top_n = np.argpartition(bm25_scores, -num_candidates)[-num_candidates:]\n",
    "    bm25_hits = [{'corpus_id': idx, 'score': bm25_scores[idx]} for idx in top_n]\n",
    "    bm25_hits = sorted(bm25_hits, key=lambda x: x['score'], reverse=True)\n",
    "\n",
    "    print(f\"Top-3 lexical search (BM25) hits\")\n",
    "    for hit in bm25_hits[0:top_k]:\n",
    "        print(\"\\t{:.3f}\\t{}\".format(hit['score'], texts[hit['corpus_id']].replace(\"\\n\", \" \")))\n",
    "\n",
    "    #Add re-ranking\n",
    "    docs = [texts[hit['corpus_id']] for hit in bm25_hits]\n",
    "\n",
    "    features = tokenizer([query for _ in docs], docs,  padding=True, truncation=True, return_tensors=\"pt\")\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        scores = model(**features).logits\n",
    "    bm25_hits_reranked = [bm25_hits[i] for i in torch.argsort(scores, dim=0, descending=True).squeeze().tolist()]\n",
    "\n",
    "    print(f\"\\nTop-3 hits by rank-API ({len(bm25_hits)} BM25 hits re-ranked)\")\n",
    "    for hit in bm25_hits_reranked[0:top_k]:\n",
    "        print(\"\\t{:.3f}\\t{}\".format(hit['score'], texts[hit['corpus_id']].replace(\"\\n\", \" \")))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1,
     "status": "ok",
     "timestamp": 1718963359073,
     "user": {
      "displayName": "Maarten Grootendorst",
      "userId": "11015108362723620659"
     },
     "user_tz": -120
    },
    "id": "9FITOXqkHONy",
    "outputId": "c4e81e12-b19c-4fa0-8ce6-7907002df7ca"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input question: location of filming\n",
      "Top-3 lexical search (BM25) hits\n",
      "\t0.000\tCinematographer Hoyte van Hoytema shot it on 35 mm movie film in the Panavision anamorphic format and IMAX 70 mm\n",
      "\t0.000\tPrincipal photography began in late 2013 and took place in Alberta, Iceland, and Los Angeles\n",
      "\t0.000\tInterstellar uses extensive practical and miniature effects and the company Double Negative created additional digital effects\n",
      "\n",
      "Top-3 hits by rank-API (10 BM25 hits re-ranked)\n",
      "\t0.000\tPrincipal photography began in late 2013 and took place in Alberta, Iceland, and Los Angeles\n",
      "\t0.000\tInterstellar premiered on October 26, 2014, in Los Angeles\n",
      "\t0.000\tCinematographer Hoyte van Hoytema shot it on 35 mm movie film in the Panavision anamorphic format and IMAX 70 mm\n"
     ]
    }
   ],
   "source": [
    "keyword_and_reranking_search(query = \"location of filming\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ugdnTs_VHV25"
   },
   "source": [
    "# Retrieval-Augmented Generation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-iqKQ7F0HZh-"
   },
   "source": [
    "## Example: Grounded Generation with an LLM API\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Not covered here, see OG notebook."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "D_25ztzEHuWX"
   },
   "source": [
    "## Example: RAG with Local Models\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jNZ5gUoWIYhp"
   },
   "source": [
    "### Loading the Generation Model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 33056,
     "status": "ok",
     "timestamp": 1718963395761,
     "user": {
      "displayName": "Maarten Grootendorst",
      "userId": "11015108362723620659"
     },
     "user_tz": -120
    },
    "id": "E4LNwOWTHvOv",
    "outputId": "945a6fa3-511d-48b7-d305-fe6d1dd23be9"
   },
   "outputs": [],
   "source": [
    "#!wget https://huggingface.co/microsoft/Phi-3-mini-4k-instruct-gguf/resolve/main/Phi-3-mini-4k-instruct-q4.gguf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "id": "a2Qgnc5OHvRQ"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "llama_context: n_batch is less than GGML_KQ_MASK_PAD - increasing to 64\n",
      "llama_context: n_ctx_per_seq (2048) < n_ctx_train (4096) -- the full capacity of the model will not be utilized\n"
     ]
    }
   ],
   "source": [
    "#from langchain import LlamaCpp # defecated\n",
    "from langchain_community.llms import LlamaCpp\n",
    "# Make sure the model path is correct for your system!\n",
    "llm = LlamaCpp(\n",
    "    model_path=\"Phi-3-mini-4k-instruct-q4.gguf\",\n",
    "    n_gpu_layers=-1,\n",
    "    max_tokens=500,\n",
    "    n_ctx=2048,\n",
    "    seed=42,\n",
    "    verbose=False\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "P06UYeIVIk1e"
   },
   "source": [
    "### The RAG Prompt\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "THESE ARE DEFECATED:\n",
    "* from langchain import PromptTemplate\n",
    "* from langchain.chains import RetrievalQA\n",
    "\n",
    "#### see https://python.langchain.com/docs/versions/migrating_chains/retrieval_qa/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "id": "F_3nTc69InwO"
   },
   "outputs": [],
   "source": [
    "from langchain import PromptTemplate\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "# Create a prompt template\n",
    "# must have {context} since below we pass context to it.\n",
    "template = \"\"\"<|user|>\n",
    "Relevant information:\n",
    "{context}\n",
    "\n",
    "Provide a concise answer the following question using the relevant information provided above:\n",
    "{question}<|end|>\n",
    "<|assistant|>\"\"\"\n",
    "prompt = PromptTemplate(\n",
    "    template=template,\n",
    "    input_variables=[\"context\", \"question\"]\n",
    ")\n",
    "\n",
    "def format_docs(docs):\n",
    "    return \"\\n\\n\".join(doc.page_content for doc in docs)\n",
    "\n",
    "\n",
    "qa_chain = (\n",
    "    {\n",
    "        \"context\": vector_store.as_retriever() | format_docs,\n",
    "        \"question\": RunnablePassthrough(),\n",
    "    }\n",
    "    | prompt\n",
    "    | llm\n",
    "    | StrOutputParser()\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note, no memory as we did not incorporate it. To have memory and be able to retrieve stuff, use retrieval as a tool instead of a pipeline.<br>\n",
    "See: https://langchain-ai.github.io/langgraph/tutorials/get-started/2-add-tools/#6-define-the-conditional_edges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 90250,
     "status": "ok",
     "timestamp": 1718963614201,
     "user": {
      "displayName": "Maarten Grootendorst",
      "userId": "11015108362723620659"
     },
     "user_tz": -120
    },
    "id": "x2p2pJPfIp16",
    "outputId": "3d284ce5-d35d-429d-fcec-a6a4a427dc05"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\" While Kelvin shares no direct connection to the information provided, Interstellar, a highly acclaimed sci-fi film directed by Christopher Nolan and featuring theoretical physicist Kip Thorne's consultations on scientific accuracy, might have captured your interest in epic science fiction.\\n\\nHowever, as this is not directly related to Kelvin (assuming you are asking for a connection based on the given data), no specific information can be provided about him within these details. If there's more context regarding who Kelvin is or his interests, I could provide further insights relevant to your inquiry.\""
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "qa_chain.invoke('My name is Kelvin.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' The movie generated over $677 million worldwide, with a total of $773 million after subsequent re-releases.'"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "qa_chain.invoke('How much monetary value was generated from this movie?')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' Your name is Christopher Nolan.'"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "qa_chain.invoke('What is my name again?')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### More verbose version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input': 'How much monetary value was generated from this movie?',\n",
       " 'context': [Document(id='10', metadata={}, page_content='The film had a worldwide gross over $677 million (and $773 million with subsequent re-releases), making it the tenth-highest grossing film of 2014'),\n",
       "  Document(id='11', metadata={}, page_content='It received acclaim for its performances, direction, screenplay, musical score, visual effects, ambition, themes, and emotional weight'),\n",
       "  Document(id='5', metadata={}, page_content='Cinematographer Hoyte van Hoytema shot it on 35 mm movie film in the Panavision anamorphic format and IMAX 70 mm'),\n",
       "  Document(id='9', metadata={}, page_content='In the United States, it was first released on film stock, expanding to venues using digital projectors')],\n",
       " 'answer': ' The movie generated a worldwide gross of over $677 million, with an additional $773 million from subsequent re-releases.'}"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.chains import create_retrieval_chain\n",
    "from langchain.chains.combine_documents import create_stuff_documents_chain\n",
    "# must have {context} and {input}.\n",
    "template = \"\"\"<|user|>\n",
    "Relevant information:\n",
    "{context}\n",
    "\n",
    "Provide a concise answer the following question using the relevant information provided above:\n",
    "{input}<|end|>\n",
    "<|assistant|>\"\"\"\n",
    "prompt = PromptTemplate(\n",
    "    template=template,\n",
    "    input_variables=[\"context\", \"input\"]\n",
    ")\n",
    "combine_docs_chain = create_stuff_documents_chain(llm, prompt=prompt)\n",
    "rag_chain = create_retrieval_chain(vector_store.as_retriever(), combine_docs_chain)\n",
    "\n",
    "rag_chain.invoke({\"input\": \"How much monetary value was generated from this movie?\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **NOTE:** Recall the current RAG setup is \n",
    "1) retrieval first (e.g. dense retrieval)\n",
    "2) LLM read contents and generate.\n",
    "\n",
    "In the book, sometimes when the search query is too verbose, we may not retrieve relevant enough documents in step 1).<br>For example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' The provided information does not include specific details about the movie \"Interstellar\"\\'s financial earnings or revenue generation. It primarily focuses on the film\\'s production, themes, and critical acclaim in various aspects such as performances, direction, screenplay, music score, visual effects, ambition, and emotional weight. Therefore, to answer your question about the movie\\'s earnings, additional research would be required beyond the given details.'"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query = \"\"\"\n",
    "We have an essay due tomorrow. We have to write about some facts about the movie Interstellar.\n",
    "I love talking about money. I could write about them. But I could also write about the science.\n",
    "Maybe. Let's do money. How much money did the movie generate?\n",
    "\"\"\"\n",
    "qa_chain.invoke(query)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To solve this, it is a good idea to use an LLM to rewrite the query into one that aids the retrieval step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "llama_context: n_batch is less than GGML_KQ_MASK_PAD - increasing to 64\n",
      "llama_context: n_ctx_per_seq (2048) < n_ctx_train (4096) -- the full capacity of the model will not be utilized\n"
     ]
    }
   ],
   "source": [
    "llm_summarizer = LlamaCpp(\n",
    "    model_path=\"Phi-3-mini-4k-instruct-q4.gguf\",\n",
    "    n_gpu_layers=-1,\n",
    "    max_tokens=500,\n",
    "    n_ctx=2048,\n",
    "    seed=42,\n",
    "    verbose=False\n",
    ")\n",
    "template = \"\"\"<|user|>\n",
    "Your task is to extract the relevant information from the question below to use as a search query:\n",
    "{question}<|end|>\n",
    "<|assistant|>\"\"\"\n",
    "question_prompt = PromptTemplate(\n",
    "    template=template,\n",
    "    input_variables=[\"question\"]\n",
    ")\n",
    "\n",
    "def print_query(query):\n",
    "    print(\"Original question:\", query)\n",
    "    concise_query = question_prompt.format(question=query)\n",
    "    print(\"Concise query for search:\", llm_summarizer.predict(concise_query))\n",
    "    return query\n",
    "\n",
    "summarization_chain = (\n",
    "    question_prompt\n",
    "    | llm_summarizer | print_query\n",
    "    | {\"context\": vector_store.as_retriever() | format_docs, \"input\": RunnablePassthrough()}\n",
    "    | prompt\n",
    "    | llm\n",
    "    | StrOutputParser()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original question:  search query: \"Interstellar movie box office earnings\"\n",
      "Concise query for search:  search query: \"Interstellar 2014 box office revenue\"\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\" I'm sorry, but the provided information does not include specific details about Interstellar's box office earnings. However, given its critical acclaim and cult following, it can be inferred that the film was financially successful to a certain extent. For precise figures on its box office performance, further research would be necessary.\""
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query = \"\"\"\n",
    "We have an essay due tomorrow. We have to write about some facts about the movie Interstellar.\n",
    "I love talking about money. I could write about them. But I could also write about the science.\n",
    "Maybe. Let's do money. How much money did the movie generate?\n",
    "\"\"\"\n",
    "summarization_chain.invoke(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' The provided information does not include specific details on \"Interstellar\" box office revenue or earnings.'"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "qa_chain.invoke('\"Interstellar\" box office revenue, earnings')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input': 'Interstellar money generated',\n",
       " 'context': [Document(id='7', metadata={}, page_content='Interstellar uses extensive practical and miniature effects and the company Double Negative created additional digital effects'),\n",
       "  Document(id='8', metadata={}, page_content='Interstellar premiered on October 26, 2014, in Los Angeles'),\n",
       "  Document(id='0', metadata={}, page_content='Interstellar is a 2014 epic science fiction film co-written, directed, and produced by Christopher Nolan'),\n",
       "  Document(id='13', metadata={}, page_content='Since its premiere, Interstellar gained a cult following,[5] and now is regarded by many sci-fi experts as one of the best science-fiction films of all time')],\n",
       " 'answer': ' The provided information does not include specific financial data on the money generated by \"Interstellar.\" However, it is a critically acclaimed film that premiered in 2014 and has garnered a cult following over time. For detailed box office earnings or revenue figures, additional research would be required.'}"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rag_chain.invoke({\"input\":'Interstellar money generated'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input': 'money generated',\n",
       " 'context': [Document(id='9', metadata={}, page_content='In the United States, it was first released on film stock, expanding to venues using digital projectors'),\n",
       "  Document(id='7', metadata={}, page_content='Interstellar uses extensive practical and miniature effects and the company Double Negative created additional digital effects'),\n",
       "  Document(id='10', metadata={}, page_content='The film had a worldwide gross over $677 million (and $773 million with subsequent re-releases), making it the tenth-highest grossing film of 2014'),\n",
       "  Document(id='4', metadata={}, page_content='Caltech theoretical physicist and 2017 Nobel laureate in Physics[4] Kip Thorne was an executive producer, acted as a scientific consultant, and wrote a tie-in book, The Science of Interstellar')],\n",
       " 'answer': ' Interstellar generated a worldwide gross of over $677 million, with an additional $773 million from subsequent re-releases.'}"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rag_chain.invoke({\"input\":'money generated'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original question:  search query: \"movie box office gross\" or \"film revenue\"\n",
      "Concise query for search:  search query: \"box office revenue of movies\" or \"film gross income\"\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "' The movie \"Interstellar\" grossed over $677 million worldwide, making it the tenth-highest earning film of 2014. It was also nominated for five awards at the 87th Academy Awards and won Best Visual Effects.'"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query = \"\"\"\n",
    "We have an essay due tomorrow. We have to write about some facts about the movie.\n",
    "I love talking about money. I could write about them. But I could also write about the science.\n",
    "Maybe. Let's do money. How much money did the movie generate?\n",
    "\"\"\"\n",
    "summarization_chain.invoke(query)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
